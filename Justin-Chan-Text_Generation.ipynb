{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 0: Justin Chan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Text Generation using RNNs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 2: Project Definition\n",
    "\n",
    "### Goals\n",
    "\n",
    "The goal of the project is to develop a recurrent neural network (RNN) capable of generating text.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "The data source used to train the RNN is \"A Tale of Two Cities\" by Charles Dickens.\n",
    "This was obtained from the Gutenberg Project, [here](https://www.gutenberg.org/files/98/98-0.txt).\n",
    "\n",
    "\n",
    "We reference the coding examples to build our RNN.\n",
    "- [Creating A Text Generator Using Recurrent Neural Network, by Trung Tran  ](https://chunml.github.io/ChunML.github.io/project/Creating-Text-Generator-Using-Recurrent-Neural-Network/)\n",
    "\n",
    "- [Chun ML's Github repo on text generation](https://github.com/ChunML/text-generator)\n",
    "\n",
    "- [The Unreasonable Effectiveness of Recurrent Neural Networks, by Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)\n",
    "\n",
    "The example provided by Karpathy showed interesting examples of how character-by-character trained and generation allowed for varied examples including generation of C code, Shakespeare etc.\n",
    "\n",
    "### Tasks\n",
    "\n",
    "We would perform the following.\n",
    "\n",
    "Example:\n",
    " \n",
    "1. Download the data.\n",
    "2. Process the data so it is suitable for input into RNN\n",
    "3. Train a recurrent neural network (LSTM) based on keras\n",
    "4. Generate examples from the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 3: Data Engineering\n",
    "\n",
    "We perform data related tasks\n",
    "\n",
    "* Manually remove irrelevant data in the beginning of the text file (eg. copyright info ).\n",
    "* Import the training text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM, SimpleRNN\n",
    "from keras.layers.wrappers import TimeDistributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#initializing some variables\n",
    "DATA_DIR = \"a_tale_of_two_cities.txt\"\n",
    "BATCH_SIZE = 50\n",
    "HIDDEN_DIM = 500\n",
    "SEQ_LENGTH = 50\n",
    "WEIGHTS = ''\n",
    "GENERATE_LENGTH = 500\n",
    "LAY "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the data\n",
    "\n",
    "We remove some irrelevant information manually before importing the text(ie. copyright from the Gutenberg Project)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = open(DATA_DIR, 'r', encoding='utf8').read()\n",
    "chars = list(set(data))\n",
    "VOCAB_SIZE = len(chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 4: Feature Engineering\n",
    "\n",
    "We create conversion functions, and also generate the X, y datasets for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create conversion functions to deal with characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conversion functions\n",
    "ix_to_char = {ix:char for ix, char in enumerate(chars)}\n",
    "char_to_ix = {char:ix for ix, char in enumerate(chars)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create X, y\n",
    "\n",
    "#initialize with zero first, but of correct dimensions\n",
    "X = np.zeros((len(data)//SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE))\n",
    "y = np.zeros((len(data)//SEQ_LENGTH, SEQ_LENGTH, VOCAB_SIZE))\n",
    "\n",
    "\n",
    "#do this for each input block\n",
    "for i in range(0, len(data)//SEQ_LENGTH):\n",
    "    X_sequence = data[i*SEQ_LENGTH:(i+1)*SEQ_LENGTH]\n",
    "    X_sequence_ix = [char_to_ix[value] for value in X_sequence]\n",
    "    input_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        input_sequence[j][X_sequence_ix[j]] = 1.\n",
    "    X[i] = input_sequence\n",
    "\n",
    "    #repeat the sequence for the y block\n",
    "    y_sequence = data[i*SEQ_LENGTH+1:(i+1)*SEQ_LENGTH+1]\n",
    "    y_sequence_ix = [char_to_ix[value] for value in y_sequence]\n",
    "    target_sequence = np.zeros((SEQ_LENGTH, VOCAB_SIZE))\n",
    "    for j in range(SEQ_LENGTH):\n",
    "        target_sequence[j][y_sequence_ix[j]] = 1.\n",
    "    y[i] = target_sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 5: Model Engineering\n",
    "\n",
    "For model engineering:\n",
    "* The RNN is based on LSTM with two layers (ie. specified by LAYER_NUM)\n",
    "* After each epoch, the model generates an output of length 500 (specified by GENERATE_LENGTH). This allows us to observe the quality and any anomalies related to the generated text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a function that can generate text from the RNN model when provided with a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_text(model, length, vocab_size, ix_to_char):\n",
    "    # starting with random character\n",
    "    ix = [np.random.randint(vocab_size)]\n",
    "    y_char = [ix_to_char[ix[-1]]]\n",
    "    X = np.zeros((1, length, vocab_size))\n",
    "    for i in range(length):\n",
    "        # appending the last predicted character to sequence\n",
    "        X[0, i, :][ix[-1]] = 1\n",
    "        print(ix_to_char[ix[-1]], end=\"\")\n",
    "        ix = np.argmax(model.predict(X[:, :i+1, :])[0], 1)\n",
    "        y_char.append(ix_to_char[ix[-1]])\n",
    "    return ('').join(y_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(HIDDEN_DIM, input_shape=(None, VOCAB_SIZE), return_sequences=True))\n",
    "for i in range(LAYER_NUM - 1):\n",
    "    model.add(LSTM(HIDDEN_DIM, return_sequences=True))\n",
    "model.add(TimeDistributed(Dense(VOCAB_SIZE)))\n",
    "model.add(Activation('softmax'))\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"rmsprop\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, None, 500)         1168000   \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, None, 500)         2002000   \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, None, 83)          41583     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, None, 83)          0         \n",
      "=================================================================\n",
      "Total params: 3,211,583\n",
      "Trainable params: 3,211,583\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model, saving checkpoints and generating text from current model during each epoch run. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Justin\\Anaconda3\\envs\\mldds\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15483/15483 [==============================] - 344s 22ms/step - loss: 0.2789\n",
      "\n",
      "\n",
      "“I have delivered that letter,” said Carton, “I wish we might be friend, I speak of see. A moment that more possible to us; if he was in no other tone, or office had been out of their domestic streets. I had had a pulpail docifes for that word!”\n",
      "\n",
      "“Come, then, my wife,” said Defarge. He looked up, and walked to and fro, and the clocks struck the\n",
      "number and dark his work.\n",
      "\n",
      "The crowd was there, and the night broke of its room, and said, “I am not surely equap.”\n",
      "\n",
      "“The timid hands he was presused t\n",
      "\n",
      "\n",
      "Epoch 1/1\n",
      "15483/15483 [==============================] - 344s 22ms/step - loss: 0.2768\n",
      "--a pity to\n",
      "live no better life?”\n",
      "\n",
      "“God knows it is stronger, who had been drinking in at the gate, struck and mild, against a rating smile that he could so depositate, instead of watchful sound of wrong, in an affection to be registered. If the bell at Lucie and the hollow revolucte of mind, Mr.\n",
      "Lorry burnt, and it was so strong and fied, and the griedy that had been taken from his port, and took her forehead on his sake, by the breast of a stander of boar in advance, the day were always in the"
     ]
    }
   ],
   "source": [
    "nb_epoch = 43\n",
    "while nb_epoch<46:\n",
    "    print('\\n\\n')\n",
    "    model.fit(X, y, batch_size=BATCH_SIZE, verbose=1, nb_epoch=1)\n",
    "    nb_epoch += 1\n",
    "    #generate_text(model, GENERATE_LENGTH)\n",
    "    generate_text(model, GENERATE_LENGTH, VOCAB_SIZE, ix_to_char)\n",
    "    #if nb_epoch % 10 == 0:\n",
    "    #    model.save_weights('checkpoint_{}_epoch_{}.hdf5'.format(HIDDEN_DIM, nb_epoch))\n",
    "    model.save_weights('checkpoint_{}_epoch_{}.hdf5'.format(HIDDEN_DIM, nb_epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 6: Evaluate Metrics\n",
    "\n",
    "We ran the models through more than 40 epochs (ie. the initial few epochs were overwritten and not saved). \n",
    "\n",
    "We can load the models at various stages and observe their outputs below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Generation from Model after 1st epoch: \n",
      "F the prisoner had been a little consideration and the sun was a change of the courtyard and the sun was a little child and the sun with his hands in the streets.\n",
      "\n",
      "“I don't know what is that this is a little minute of the prisoner when I will go to the prisoner in the courtyard that I have been a little morning, that I will not be and the prisoner in the courtyard that I have been a little morning, that I will not be and the prisoner in the courtyard that I have been a little morning, that I wil"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"F the prisoner had been a little consideration and the sun was a change of the courtyard and the sun was a little child and the sun with his hands in the streets.\\n\\n“I don't know what is that this is a little minute of the prisoner when I will go to the prisoner in the courtyard that I have been a little morning, that I will not be and the prisoner in the courtyard that I have been a little morning, that I will not be and the prisoner in the courtyard that I have been a little morning, that I will\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Model after epoch 1\n",
    "model_epoch1 = load_model('my_model.h5')\n",
    "model_epoch1.load_weights('checkpoint_500_epoch_1.hdf5')\n",
    "print(\"Text Generation from Model after 1st epoch: \")\n",
    "generate_text(model_epoch1, GENERATE_LENGTH, VOCAB_SIZE, ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Generation from Model after 10th epoch: \n",
      "_ he said it with the last side, burnt on the stairs and close to himself, and was soon with the air. He had not been seen of the words were by the first to see the window, and she sat up again at the bench of his work, that he would not be\n",
      "released and drawn to the black brother, as the fountain at all a stair and fancy, and was drawing him and her hand on his bench and the chance flowed on her breast, as if they were at seat, and was soon the little counter, and showed itself in his breast of "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'_ he said it with the last side, burnt on the stairs and close to himself, and was soon with the air. He had not been seen of the words were by the first to see the window, and she sat up again at the bench of his work, that he would not be\\nreleased and drawn to the black brother, as the fountain at all a stair and fancy, and was drawing him and her hand on his bench and the chance flowed on her breast, as if they were at seat, and was soon the little counter, and showed itself in his breast of t'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Model after epoch 10\n",
    "model_epoch10 = load_model('my_model.h5')\n",
    "model_epoch10.load_weights('checkpoint_500_epoch_10.hdf5')\n",
    "print(\"Text Generation from Model after 10th epoch: \")\n",
    "generate_text(model_epoch10, GENERATE_LENGTH, VOCAB_SIZE, ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Generation from Model after 20th epoch: \n",
      "Lorry was a pleasant sight too,\n",
      "beaming at all this on the body as stopped by a low before it, and might have been a solemn interest in the eyes, and the clock struck at him, the first cause of the stairs were as tention of the life of her life and hope they were always with his flopping like a fireness to the days before the family, and a tender pass of the house for the little\n",
      "counter, as if the airsed of a flamin will with a rady groun, and shine of the landscape, turned for the worse to the "
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Lorry was a pleasant sight too,\\nbeaming at all this on the body as stopped by a low before it, and might have been a solemn interest in the eyes, and the clock struck at him, the first cause of the stairs were as tention of the life of her life and hope they were always with his flopping like a fireness to the days before the family, and a tender pass of the house for the little\\ncounter, as if the airsed of a flamin will with a rady groun, and shine of the landscape, turned for the worse to the s'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Model after epoch 20\n",
    "model_epoch20 = load_model('my_model.h5')\n",
    "model_epoch20.load_weights('checkpoint_500_epoch_20.hdf5')\n",
    "print(\"Text Generation from Model after 20th epoch: \")\n",
    "generate_text(model_epoch20, GENERATE_LENGTH, VOCAB_SIZE, ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Generation from Model after 30th epoch: \n",
      "9”\n",
      "\n",
      "“Since it is my husband?” said Madame Defarge. “I have the honour of counself and superiors when he saw the passage ladyed on a short notice, for you are provided on business who says it is (a moment, and where a quantic straight continuty of the coach arrs. A feir of his voice and\n",
      "he precious at drank and dancer passed for a man who read house, and his hear was closed out of the street, and not one with barber, and write on the scafful body as if there had been taken estated at him, and alw"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'9”\\n\\n“Since it is my husband?” said Madame Defarge. “I have the honour of counself and superiors when he saw the passage ladyed on a short notice, for you are provided on business who says it is (a moment, and where a quantic straight continuty of the coach arrs. A feir of his voice and\\nhe precious at drank and dancer passed for a man who read house, and his hear was closed out of the street, and not one with barber, and write on the scafful body as if there had been taken estated at him, and alwa'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Model after epoch 30\n",
    "model_epoch30 = load_model('my_model.h5')\n",
    "model_epoch30.load_weights('checkpoint_500_epoch_30.hdf5')\n",
    "print(\"Text Generation from Model after 30th epoch: \")\n",
    "generate_text(model_epoch30, GENERATE_LENGTH, VOCAB_SIZE, ix_to_char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Generation from Model after 40th epoch: \n",
      "You want\n",
      "a promise from me. A man what I had done, eyebrous for me; my nephew,” said Defarge, with a watch of time when the postilions had come over her hand. An\n",
      "horring in the further changed torn would only hear the extraorde in its coach and grass, had been heavy count of viving access to or, as if\n",
      "his dame been to any of the two touch some days when it was necessary to be done, and holding the penderingement were so confused. As his lips of the triumphs of the face was desired in to\n",
      "work upo"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'You want\\na promise from me. A man what I had done, eyebrous for me; my nephew,” said Defarge, with a watch of time when the postilions had come over her hand. An\\nhorring in the further changed torn would only hear the extraorde in its coach and grass, had been heavy count of viving access to or, as if\\nhis dame been to any of the two touch some days when it was necessary to be done, and holding the penderingement were so confused. As his lips of the triumphs of the face was desired in to\\nwork upon'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Model after epoch 40\n",
    "model_epoch40 = load_model('my_model.h5')\n",
    "model_epoch40.load_weights('checkpoint_500_epoch_40.hdf5')\n",
    "print(\"Text Generation from Model after 40th epoch: \")\n",
    "generate_text(model_epoch40, GENERATE_LENGTH, VOCAB_SIZE, ix_to_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 7: Observations and analysis\n",
    "\n",
    "Answer the following questions:\n",
    "1. What do you conclude from the metrics?\n",
    "\n",
    "2. If the metrics are not good, try to find out what is the reason in order to improve the model. What kind of inputs does the model not do well? (i.e. what are the blind spots or invalid assumptions?). Note that to answer this question, you need to decide what a \"good\" result is for your problem formulation.\n",
    "\n",
    "3. What improvements do you propose?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "We can observe several aspects from the output from the model.\n",
    "\n",
    "* Early epochs generated text with repeated sequences. For the model after epoch 1, it repeated \"I will not be and the prisoner in the courtyard that I have been a little morning\" several times. Later epochs had less of such repetitions.\n",
    "\n",
    "* Early epoch generated text with less spelling errors. This may be due to the memory of a limited, but well-learnt vocabulary which it tends not to deviate from.\n",
    "\n",
    "* New line breaks are a challenge for the model to learn.\n",
    "\n",
    "* The model can learn punctuations, particularly direct speech. It would know to:\n",
    "    * generate both open and closing quotes.\n",
    "    * end a sentence within the quotes with a comma (instead of fullstop)\n",
    "    * follow the direct speech with 'said' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Areas of improvement include:\n",
    "\n",
    "* Use of a machine with GPU (as the training takes a lot of time).\n",
    "* Use more hidden layers which may improve the results\n",
    "* Train for more epochs. The references mentioned that researchers had used up to 200 epochs in order to train good models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Areas to explore include:\n",
    "\n",
    "* Experiment to see if the generated text creates the same word2vec structure as the original text. \n",
    "We try to determine if RNNs can learn similar 'word associations' if trained long enough.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
